# ğŸ”± Agent VyÄsa â€” The Conversational Memory Oracle

> _"Speak, and I shall listen. Ask, and I shall retrieve."_

**Agent VyÄsa** is a CLI-based intelligent agent that merges memory, retrieval, and real-time inference to create a human-like conversation experience. Designed for deep inquiry, historical memory recall, and source-based answers, VyÄsa is not just a chatbot â€” it's an evolving digital companion.

---

## âœ¨ Features

### ğŸ§  Semantic Memory with Redis
- Stores and retrieves semantically indexed conversations.
- Memory is trimmed and rotated to preserve context without overloading.
- Memory retrieval works via keyword query or automated loading on session resume.

### ğŸ§¾ Chat Session Management
- Each chat is treated as a **session** identified by a UUID.
- Users can:
  - `âœ¨ create session` â€” Start a new chat with a title.
  - `ğŸ“‚ select session` â€” Resume from existing saved chats.
  - `ğŸ§  load memory` â€” Inject past context into the current session.

### ğŸ” Deep Search: Tathya
- Ask `Tathya: <your query>` to invoke RAG (Retrieval-Augmented Generation).
- Uses external sources and memory to form rich, contextually backed answers.

### ğŸ§­ Beautiful CLI Interface
- Built using `rich` for stunning visuals:
  - Boxed panels for welcome messages.
  - Center-aligned instructions.
  - Colored session listings and guide menu.

### ğŸ§° Modular Architecture
- Node-based execution (`bot_node`, `tathya_node`, etc.).
- Redis for fast cache.
- PostgreSQL via SQLAlchemy for long-term storage.
- LangChain + Ollama (Mistral) as the LLM interface.

---

## ğŸ§  Memory Architecture

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Chatbot Agent        â”‚
â”‚        (LangChain + LLM)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚   Redis   â”‚ â—„â”€â”€â”€â–º Semantic Cache (Recent Context: 20 Messages Max)
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ PostgreSQL  â”‚ â—„â”€â”€â”€â–º Long-Term Storage (ChatSessions, ChatMessages)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Short-Term Memory: Redis stores the last 20 messages for blazing fast access.
- Long-Term Memory: Synced to PostgreSQL when session ends or memory is flushed.
- Context Injection: RAG can enrich context from memory or external tools (via Tathya).


ğŸ–¥ï¸ CLI Command Guide
- âœ¨ new session        â†’ Begin a fresh chat thread.
- ğŸ“‚ select session     â†’ View and resume past chats.
- ğŸ§  load memory        â†’ Inject remembered messages into current context.
- ğŸ” Tathya: <query>    â†’ Perform RAG-based answer with external search.
- ğŸ§­ menu               â†’ Show this command menu again.
- âŒ end                â†’ Close the session and flush memory if needed.

## ğŸ—ï¸ Stack Used

- ğŸ§  **[LangChain](https://www.langchain.com/)**  
  Framework for chaining LLMs with memory, tools, and more.

- ğŸ¤– **[Ollama (Mistral)](https://ollama.com/)**  
  Lightweight local LLM backend serving the Mistral model.

- ğŸ˜ **[PostgreSQL](https://www.postgresql.org/)** + ğŸ§¾ **[SQLAlchemy](https://www.sqlalchemy.org/)**  
  Robust relational database and Python ORM for storing sessions and messages.

- ğŸ”„ **[Redis](https://redis.io/)** *(via Docker)*  
  Fast in-memory cache for recent chat history and temporary context.

- ğŸ¨ **[Rich](https://github.com/Textualize/rich)**  
  Terminal formatting library used for stylish CLI rendering.

- ğŸš€ **[FastAPI](https://fastapi.tiangolo.com/)** *(Planned)*  
  A high-performance async framework for the upcoming API interface.

## âš™ï¸ Setup Instructions

Follow the steps below to get Agent **VyÄsa** up and running locally.

---

### ğŸ“ 1. Clone the Repository

```bash
git clone https://github.com/yourusername/vyasa.git
cd vyasa

ğŸ 2. Create Virtual Environment & Install Dependencies
Make sure you're using Python 3.10+.
python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt

ğŸ§  3. Start Ollama with Mistral
Install Ollama if not already installed.

ğŸ˜ 4. Setup PostgreSQL Database
Ensure PostgreSQL is running locally. Then:
createdb vyasa_db
DATABASE_URL=postgresql://username:password@localhost:5432/vyasa_db
docker run -d --name vyasa-redis -p 6379:6379 redis

ğŸ¨ 6. Run the CLI Agent
Once everything is ready, start VyÄsaâ€™s CLI interface:
python main.py


*Developed by: Swastik Das*
_With inspiration from Vedantic wisdom and the need for meaningful memory in AI._
